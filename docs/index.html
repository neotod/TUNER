<!DOCTYPE html>
<meta charset="utf-8">

<html>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
    width: 980px;
}
h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #1367a7;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1, h2, h3 {
    text-align: center;
}
h1 {
    font-size: 40px;
    font-weight: 500;
}
h2, h3 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
.paper-title {
    padding: 16px 0px 16px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.row, .author-row, .affil-row {
     overflow: auto;
}
.author-row, .affil-row {
    font-size: 20px;
}
.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 18px;
}
.affil-row {
    margin-top: 16px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-lg {
    width: 512px;
    border: 1px solid #ddd;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
.screenshot-elg {
    width: 100%;
    border: 1px solid #ddd;
    display: block;
    margin-left: auto;
    margin-right: auto;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0;
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption_justify {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: justify;
    margin-top: 0px;
    margin-bottom: 64px;
}
.caption {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 64px;
}
.caption_inline {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 8px;
    margin-bottom: 0px;
}
.caption_bold {
    font-size: 16px;
    /*font-style: italic;*/
    color: #666;
    text-align: center;
    margin-top: 0px;
    margin-bottom: 0px;
    font-weight: bold;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    justify-content: space-around;
    padding: 0;
    margin: 0;
    list-style: none;
}
.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;

  background-color: #1367a7;
  color: #ecf0f1 !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}
.paper-btn:hover {
    opacity: 0.85;
}
.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}
.venue {
    color: #1367a7;
}
</style>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title>Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks</title>
    <meta property="og:description" content="Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks"/>
    <meta property="og:image" itemprop="image" content="https://dsilvavinicius.github.io/differential_geometry_in_neural_implicits/assets/representative.JPEG">
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@dsilvavinicius">
    <meta name="twitter:title" content="Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks">
    <meta name="twitter:description" content="A new paper which bridges Discrete Differential Geometry in meshes and (Continuous) Differential Geometry in Neural Implicits.">
    <meta name="twitter:image" content="https://dsilvavinicius.github.io/differential_geometry_in_neural_implicits/assets/representative.JPEG">
</head>


<body>
<div class="container">
    <div class="paper-title">
        <h1>Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks</h1>
    </div>

    <div id="authors">
        <div class="author-row">
            <div class="col-4 text-center"><a href="https://sites.google.com/site/tiagonovellodebrito">Tiago Novello</a><sup>1, 2*</sup></div>
            <div class="col-4 text-center"><a href="https://scholar.google.com/citations?user=UBfNGnMAAAAJ&hl=en&oi=ao">Diana Aldana</a><sup>1*</sup></div>
            <div class="col-4 text-center"><a href="https://andrefaraujo.github.io/">Andre Araujo</a><sup>2</sup></div>
            <div class="col-4 text-center"><a href="https://lvelho.impa.br/">Luiz Velho</a><sup>1</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-2 text-center"><sup>1</sup>IMPA</div>
            <div class="col-2 text-center"><sup>2</sup>Google DeepMind</div>
        </div>

        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="paper-btn" href="assets/Novello_Tuning_the_Frequencies_Robust_Training_for_Sinusoidal_Neural_Networks_CVPR_2025_paper.pdf">
                    <span class="material-icons"> description </span>
                    Paper
                </a>
                <a class="paper-btn" href="assets/Novello_Tuning_the_Frequencies_CVPR_2025_supplemental.pdf">
                    <span class="material-icons"> description </span>
                    Supp
                </a>
                <a class="paper-btn" href="https://github.com/DianaPat/TUNER">
                    <span class="material-icons"> code </span>
                    Code
                </a>
                <a class="paper-btn" href="assets/TUNER-CVPR-poster.pdf">
                    <span class="material-icons"> image </span>
                    Poster
                </a>
                <!-- <a class="paper-btn" href="">
                    <span class="material-icons"> videocam </span>
                    Soon
                </a> -->
            </div>
        </div>
    </div>

    <section id="teaser-videos">
        <!--
        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Coarse
            </p>
        </figure>

        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Neural Implicit Normal Mapping
            </p>
        </figure>

        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Baseline
            </p>
        </figure>
        -->

        <figure style="width: 60%; float: center">
            <img class="screenshot-elg" src="assets/teaser.jpg">
        </figure>

        <!-- <figure style="width: 100%; float: left">
            <p class="caption_justify">
                Armadillo curvature rendering. An important advantage of using neural implicit functions to represent surfaces is that we can compute their differentiable objects analytically. The image was generated using a transfer function to visualize the gaussian and mean curvatures of the neural surface. This function relates points with high/medium/low curvatures to the red/white/blue colors. Our model enables both normal vectors and mean curvature to be calculated analytically through their formulas using <code>torch.autograd</code>.
            </p>
        </figure>

        <figure style="width: 100%; float: left">
            <video class="centered" width="100%" autoplay muted loop playsinline>
                <source src="assets/teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>

        <figure style="width: 100%; float: left">
            <p class="caption_justify">
                Stanford Bunny, Dragon, Armadillo and Happy Buddha trained with the proposed framework.
            </p>
        </figure> -->
    </section>

    <section id="abstract"/>
        <h2>Abstract</h2>
        <hr>
    <p>
        Sinusoidal neural networks have been shown effective as implicit neural representations (INRs) of low-dimensional signals, due to their smoothness and high representation capacity. However, initializing and training them remain empirical tasks which lack on deeper understanding to guide the learning process. To fill this gap, our work introduces a theoretical framework that explains the capacity property of sinusoidal networks and offers robust control mechanisms for initialization and training. Our analysis is based on a novel amplitude-phase expansion of the sinusoidal multilayer perceptron, showing how its layer compositions produce a large number of new frequencies expressed as integer combinations of the input frequencies. This relationship can be directly used to initialize the input neurons, as a form of spectral sampling, and to bound the networkâ€™s spectrum while training. Our method, referred to as TUNER (TUNing sinusoidal nEtwoRks), greatly improves the stability and convergence of sinusoidal INR training, leading to detailed reconstructions, while preventing overfitting.
    </p>
    </section>

    <section id="overview"/>
        <h2>Overview</h2>
        <hr>
        <p>
            We present a theoretical analysis of sinusoidal neural networks, introducing a novel trigonometric identity that expands hidden neurons into a sum of sines with frequencies formed by integer combinations of the input frequencies. This expansion yields a practical upper bound on amplitude, offering control over the spectrum at training.
            <br>
            Leveraging this insight, we develop a principled initialization scheme that accelerates training by setting input and hidden weights in accordance with their spectral roles. Furthermore, we propose a bandlimit control strategy that bounds hidden weights during optimization, leading to more stable and efficient training of sinusoidal implicit neural representations.
        
            <figure style="width: 100%; float: center">
            <img class="screenshot-elg" src="assets/overview.jpg">
        </figure>
        </p>
    </section>

    <section id="results">
        <h2>Results</h2>
        <hr>

        <div>
            <div class="col-2 text-center">
                <h3>Improved convergence</h3>
                <hr>
                <figure style="width: 100%; float: center">
                    <img class="screenshot-elg" src="assets/convergence_2.jpg">
                </figure>

            </div>

            <div class="col-2 text-center">
                <h3>Spectrum bandlimiting</h3>
                <hr>

                <figure style="width: 100%; float: center">
                    <img class="screenshot-elg" src="assets/boundings.jpg">
                </figure>
            </div>
        </div>
    </section>

    <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="assets/Novello_Tuning_the_Frequencies_Robust_Training_for_Sinusoidal_Neural_Networks_CVPR_2025_paper.pdf"><img class="screenshot" src="assets/tuner_thumbnail-1.png"></a>
            </div>
            <div style="width: 60%">
                <p><b>Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks</b></p>
                <p>Tiago Novello, Diana Aldana, Andre Araujo, and Luiz Velho</p>

                <div><span class="material-icons"> description </span><a href="assets/Novello_Tuning_the_Frequencies_Robust_Training_for_Sinusoidal_Neural_Networks_CVPR_2025_paper.pdf"> Paper preprint (PDF, 7.2 MB)</a></div>
                <div><span class="material-icons"> description </span><a href="https://arxiv.org/pdf/2407.21121"> arXiv version</a></div>
                <div><span class="material-icons"> image </span><a href="assets/TUNER-CVPR-poster.pdf"> Poster</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/novello2025tuning.bib"> BibTeX</a></div>
                <!-- <div><span class="material-icons"> videocam </span><a href=""> Soon</a></div> -->

                <p>Please send feedback and questions to <a href="https://sites.google.com/site/tiagonovellodebrito">Tiago Novello</a>.</p>
            </div>
        </div>
    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@InProceedings{Novello_2025_CVPR,
    author    = {Novello, Tiago and Aldana, Diana and Araujo, Andre and Velho, Luiz},
    title     = {Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks},
    booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR)},
    month     = {June},
    year      = {2025},
    pages     = {3071-3080}
}</code></pre>
    </section>
</div>
</body>

</html>